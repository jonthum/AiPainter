{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMupljTRgAszLn3WL+qWPq1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi_ZTLIRVPai"
      },
      "source": [
        "#COLAB - mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF94-AZZVYg-"
      },
      "source": [
        "\n",
        "#IMAGE ANALYSIS FOR STYLEGAN PAINTINGS GENERATED BY CUSTOM TRAINED STYLEGAN2 MODELS\n",
        "#by JON THUM\n",
        "\n",
        "\n",
        "!git clone https://github.com/jonthum/AiPainter\n",
        "%cd AiPainter\n",
        "\n",
        "#COLAB - root directory\n",
        "ROOT_DIR = 'AiPainter/'\n",
        "\n",
        "#COLAB - import .py files\n",
        "import sys\n",
        "SG2_DIR = ROOT_DIR + 'lib/stylegan2/'\n",
        "sys.path.append(SG2_DIR)\n",
        "\n",
        "#CHECK TF SETTINGS\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "#print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "\n",
        "#IMPORT LIBRARIES\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import pickle\n",
        "\n",
        "Gmodels = []\n",
        "\n",
        "#LIMIT TF MEMORY USE\n",
        "cfg = dict()\n",
        "cfg[\"gpu_options.per_process_gpu_memory_fraction\"]=0.2\n",
        "tflib.init_tf(cfg)\n",
        "\n",
        "#DOWNLOAD CUSTOM SG2 MODELS\n",
        "print('Downloading SG2 models ..')\n",
        "!gdown --id 1-4vOSwOjEn6bRkirUDm9pzPTI1mr10Rb -q\n",
        "!gdown --id 1-5CurIFM-sEprbytN0bWtlZ8HxXeESXY -q\n",
        "!gdown --id 1-FJoffvHQffJtlzz6t725PJnbvFQLJdR -q\n",
        "!gdown --id 1-HJI2gegpAXJGi7odlxKVKvESTGCtadZ -q\n",
        "!gdown --id 1-K2oUvzk3AphYq1QoymrHoDwyp_JiP5I -q\n",
        "\n",
        "#LOAD SG2 MODELS\n",
        "print('Loading SG2 models ..')\n",
        "with open('networkA_Gs.pkl', 'rb') as f:\n",
        "    Gs = pickle.load(f)\n",
        "Gmodels.append(Gs)\n",
        "print('Loaded model A')\n",
        "\n",
        "with open('networkB_Gs.pkl', 'rb') as f:\n",
        "    Gs = pickle.load(f)\n",
        "Gmodels.append(Gs)\n",
        "print('Loaded model B')\n",
        "\n",
        "with open('networkC_Gs.pkl', 'rb') as f:\n",
        "    Gs = pickle.load(f)\n",
        "Gmodels.append(Gs)\n",
        "print('Loaded model C')\n",
        "\n",
        "with open('networkD_Gs.pkl', 'rb') as f:\n",
        "    Gs = pickle.load(f)\n",
        "Gmodels.append(Gs)\n",
        "print('Loaded model D')\n",
        "\n",
        "with open('networkE_Gs.pkl', 'rb') as f:\n",
        "    Gs = pickle.load(f)\n",
        "Gmodels.append(Gs)\n",
        "print('Loaded model E')\n",
        "print('SG2 models loaded')\n",
        "\n",
        "#Model dictionary\n",
        "MODEL = {0:'A', 1:'B', 2:'C', 3:'D', 4:'E'}\n",
        "\n",
        "#IMPORT LIBRARIES\n",
        "import os\n",
        "import os.path\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image, ImageFilter, ImageStat, ImageChops, ImageMath\n",
        "import statistics as st\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4f8FxA_W14a"
      },
      "source": [
        "#IMAGE ANALYSIS AND FACE DETECTION FOR 5 MODELS - SAVE IN NUMPY FILES\n",
        "\n",
        "\n",
        "#HSV COLOUR HUES  \n",
        "colour = {'red': 255, 'yellow': 42, 'green': 85, 'cyan': 127, 'blue':170, 'magenta': 212}\n",
        "centre = 0\n",
        "\n",
        "#KEY HUE VALUES\n",
        "def hue_key(x):\n",
        "    global centre\n",
        "    radius = 43     #max 127\n",
        "    \n",
        "    #Shift everything to origin at 128 to avoid negative numbers    \n",
        "    y = (x-centre+128)%255       \n",
        "    key = int(3*(radius - abs(y-128)))\n",
        "    key = max(key, 0)   \n",
        "    \n",
        "    return key\n",
        "\n",
        "#MEAN VALUE FOR SPECIFIED COLOUR = HUE KEY x SAT x VAL\n",
        "def colour_stat(hue, sat, val):\n",
        "    key = Image.eval(hue, hue_key)\n",
        "    col = ImageMath.eval(\"convert(a*b/255, 'L')\", a=key, b=sat)\n",
        "    colval = ImageMath.eval(\"convert(a*b/255, 'L')\", a=col, b=val)\n",
        "    stat = ImageStat.Stat(colval)\n",
        "    \n",
        "    return stat.mean[0]\n",
        "\n",
        "\n",
        "#GENERATE IMAGE FROM MODEL\n",
        "def generate_painting(seed, artstyle):\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    latent = rnd.randn(1, Gmodels[artstyle].input_shape[1]) \n",
        "    images = Gmodels[artstyle].run(latent, None, truncation_psi=1.0, randomize_noise=False, output_transform=fmt)\n",
        "    return images[0]\n",
        "\n",
        "#MODEL ARGS\n",
        "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "Gs_syn_kwargs = dnnlib.EasyDict()\n",
        "Gs_syn_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "Gs_syn_kwargs.minibatch_size = 1\n",
        "\n",
        "\n",
        "#INIT\n",
        "start = time.process_time()\n",
        "print('Processing ....')\n",
        "DATA_DIR = ROOT_DIR + 'custom/imageanalysis/'\n",
        "\n",
        "#FACE DETECT\n",
        "faceCascade = cv2.CascadeClassifier(DATA_DIR + 'haarcascade_frontalface_default.xml')\n",
        "MIN_SIZE = 200   #Only detect faces bigger than 200x200\n",
        "\n",
        "#INCLUSIVE RANGE\n",
        "START = 0\n",
        "END = 5000\n",
        "\n",
        "\n",
        "#LOOP MODELS\n",
        "for model in range(5):\n",
        "  \n",
        "    datafile = []\n",
        "\n",
        "    #LOOP THROUGH IMAGES\n",
        "    for id in range(START, END+1):\n",
        "\n",
        "        #PROGRESS FEEDBACK\n",
        "        if(id%500 == 0):\n",
        "            print('{} images:'.format(id), time.process_time() - start)\n",
        "       \n",
        "        #GENERATE PAINTING\n",
        "        painting = generate_painting(id, model)\n",
        "        image = Image.fromarray(painting)\n",
        "\n",
        "        #FACE DETECT\n",
        "        cv2image = np.array(image)\n",
        "        gray = cv2.cvtColor(cv2image, cv2.COLOR_RGB2GRAY)\n",
        "        faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, \\\n",
        "                                             minSize=(MIN_SIZE, MIN_SIZE))\n",
        "        num_faces = len(faces)\n",
        "        if (num_faces):\n",
        "            print('{} faces detected id {}'.format(num_faces, id))\n",
        "\n",
        "        #DETAIL ANALYSIS\n",
        "        grey = image.convert('L')\n",
        "        blur = grey.filter(ImageFilter.GaussianBlur(10))\n",
        "        diff = ImageChops.difference(grey, blur)\n",
        "        \n",
        "        D = 4   #Normalising constant\n",
        "        stat = ImageStat.Stat(diff)\n",
        "        detail = int(D*stat.mean[0])\n",
        "        \n",
        "        \n",
        "        #DOWNSIZE TO SAVE COMPUTATION\n",
        "        image = image.resize((128,128))\n",
        "      \n",
        "        \n",
        "        #HSV ANALYSIS\n",
        "        hsv = image.convert(mode=\"HSV\")\n",
        "        \n",
        "        hue = hsv.getchannel('H')\n",
        "        sat = hsv.getchannel('S')\n",
        "        val = hsv.getchannel('V')\n",
        "     \n",
        "        stat = ImageStat.Stat(hsv)\n",
        "        brightness = int(stat.mean[2]/2)\n",
        "        contrast = int(stat.stddev[2])\n",
        "        saturation = int(stat.mean[1]/2)\n",
        "        \n",
        "    \n",
        "        #INDIVIDUAL COLOUR ANALYSIS\n",
        "        C = 8   #Normalising constant\n",
        "        \n",
        "        centre = colour['red']\n",
        "        red_mean = int(C*colour_stat(hue, sat, val))\n",
        "        \n",
        "        centre = colour['yellow']\n",
        "        yellow_mean = int(C*colour_stat(hue, sat, val))\n",
        "        \n",
        "        centre = colour['green']\n",
        "        green_mean = int(C*colour_stat(hue, sat, val))\n",
        "        \n",
        "        centre = colour['cyan']\n",
        "        cyan_mean = int(C*colour_stat(hue, sat, val))\n",
        "        \n",
        "        centre = colour['blue']\n",
        "        blue_mean = int(C*colour_stat(hue, sat, val))\n",
        "        \n",
        "        centre = colour['magenta']\n",
        "        magenta_mean = int(C*colour_stat(hue, sat, val))\n",
        "    \n",
        "    \n",
        "        #COLOUR VARIETY\n",
        "        T = 60  #Max value to determine completeness\n",
        "        \n",
        "        col_means = [red_mean, yellow_mean, green_mean, cyan_mean, blue_mean, magenta_mean]\n",
        "        mean = st.mean(col_means)\n",
        "        stdev = st.stdev(col_means)\n",
        "        total = min(red_mean, T) + min(yellow_mean, T) + min(green_mean, T) + \\\n",
        "                min(cyan_mean, T) + min(blue_mean, T) + min(magenta_mean, T)\n",
        "        variety = int(total*mean/(stdev+1)/2)    \n",
        "                \n",
        "        #APPEND DATA\n",
        "        info = [detail, brightness, contrast, saturation, variety, \n",
        "                red_mean, yellow_mean, green_mean, \n",
        "                cyan_mean, blue_mean, magenta_mean, num_faces, id]\n",
        "        #print(info)\n",
        "        datafile.append(info)        \n",
        "        \n",
        "\n",
        "    #SAVE DATA\n",
        "    datafile = np.array(datafile, dtype=np.int)\n",
        "    name = 'ImageAnalysis1_{}.npy'.format(MODEL[model])\n",
        "    np.save(DATA_DIR + name, datafile)\n",
        "    print(datafile.shape)\n",
        "\n",
        "    print('END:', time.process_time() - start)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL25zOe1tHdk"
      },
      "source": [
        "#PROGRAM TO CORRELATE FACE DETECTION AMONGST MODELS \n",
        "#SET ALL TO ONE IF DETECTED IN MORE THAN 2 MODELS, ELSE SET ALL TO ZERO\n",
        "\n",
        "DATA_DIR = ROOT_DIR + 'custom/imageanalysis/'\n",
        "\n",
        "#LOAD IMAGE ANALYSIS FILES\n",
        "datafiles = []\n",
        "datafiles.append(np.load(ROOT_DIR + 'custom/imageanalysis/ImageAnalysis1_A.npy'))\n",
        "datafiles.append(np.load(ROOT_DIR + 'custom/imageanalysis/ImageAnalysis1_B.npy'))\n",
        "datafiles.append(np.load(ROOT_DIR + 'custom/imageanalysis/ImageAnalysis1_C.npy'))\n",
        "datafiles.append(np.load(ROOT_DIR + 'custom/imageanalysis/ImageAnalysis1_D.npy'))\n",
        "datafiles.append(np.load(ROOT_DIR + 'custom/imageanalysis/ImageAnalysis1_E.npy'))\n",
        "\n",
        "num = len(datafiles[0]) #20\n",
        "print(num)\n",
        "\n",
        "for i in range(num):\n",
        "\n",
        "    #CHECK HOW MANY MODELS FOUND FACES\n",
        "    faces = 0\n",
        "    for model in range(5):\n",
        "        faces += datafiles[model][i,11] \n",
        "        #print(datafiles[model][i,11], end='')\n",
        "    #print('= {}'.format(faces))\n",
        "\n",
        "    #IF MORE THAN 2 FACES DETECTED SET ALL TO 1 \n",
        "    if (faces>2):\n",
        "        for model in range(5):\n",
        "            datafiles[model][i,11] = 1\n",
        "    #ELSE SET ALL TO 0\n",
        "    else:\n",
        "        for model in range(5):\n",
        "            datafiles[model][i,11] = 0\n",
        "\n",
        "    #CHECK\n",
        "    #for model in range(5):\n",
        "        #print(datafiles[model][i,11], end='')\n",
        "    #print('')\n",
        "\n",
        "\n",
        "#SAVE DATA\n",
        "for model in range(5):\n",
        "    name = 'ImageAnalysis2_{}.npy'.format(MODEL[model])\n",
        "    np.save(DATA_DIR + name, datafiles[model])\n",
        "    print(datafiles[model].shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}